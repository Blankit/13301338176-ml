<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Microsoft FrontPage 6.0">
   <meta name="Author" content="Todd Neller">
   <title>CS 391 Home Page</title>
</head>
<body bgcolor="#FFFFFF">
<table WIDTH="100%" >
<tr>
<td><img SRC="GburgCS.gif" height=84 width=182></td>

<td><font size=+2>CS 391 - Selected Topics: Data Mining</font>
<br><font size=+2>Syllabus</font></td>
</tr>
</table>

<hr>[From <a href="http://www.cs.waikato.ac.nz/~ml/weka/book.html">
http://www.cs.waikato.ac.nz/~ml/weka/book.html</a>:]
<p><b>Part I: Practical Machine Learning Tools and Techniques</b><br>
<br>
<b>1. What&#8217;s it all about?</b><br>
1.1 Data mining and machine learning<br>
1.2 Simple examples: the weather problem and others<br>
1.3 Fielded applications<br>
1.4 Machine learning and statistics<br>
1.5 Generalization as search<br>
1.6 Data mining and ethics<br>
1.7 Further reading<br>
<br>
<b>2. Input: Concepts, instances, attributes</b><br>
2.1 What&#8217;s a concept?<br>
2.2 What&#8217;s in an example?<br>
2.3 What&#8217;s in an attribute?<br>
2.4 Preparing the input<br>
2.5 Further reading<br>
<br>
<b>3. Output: Knowledge representation</b><br>
3.1 Decision tables<br>
3.2 Decision trees<br>
3.3 Classification rules<br>
3.4 Association rules<br>
3.5 Rules with exceptions<br>
3.6 Rules involving relations<br>
3.7 Trees for numeric prediction<br>
3.8 Instance-based representation<br>
3.9 Clusters<br>
3.10 Further reading<br>
<br>
<b>4. Algorithms: The basic methods</b><br>
4.1 Inferring rudimentary rules<br>
4.2 Statistical modeling<br>
4.3 Divide-and-conquer: constructing decision trees<br>
4.4 Covering algorithms: constructing rules<br>
4.5 Mining association rules<br>
4.6 Linear models<br>
4.7 Instance-based learning<br>
4.8 Clustering<br>
4.9 Further reading<br>
<br>
<b>5. Credibility: Evaluating what&#8217;s been learned</b><br>
5.1 Training and testing<br>
5.2 Predicting performance<br>
5.3 Cross-validation<br>
5.4 Other estimates<br>
5.5 Comparing data mining schemes<br>
5.6 Predicting probabilities<br>
5.7 Counting the cost<br>
5.8 Evaluating numeric prediction<br>
5.9 The minimum description length principle<br>
5.10 Applying MDL to clustering<br>
5.11 Further reading<br>
<br>
<b>6. Implementations: Real machine learning schemes</b><br>
6.1 Decision trees<br>
6.2 Classification rules<br>
6.3 Extending linear models<br>
6.4 Instance-based learning<br>
6.5 Numeric prediction<br>
6.6 Clustering<br>
6.7 Bayesian networks</p>
<p>We will also cover selected portions of Part II involving the WEKA software 
workbench.</p>

</body>
</html>
