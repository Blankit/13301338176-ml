<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Microsoft FrontPage 4.0">
   <meta name="Author" content="Todd Neller">
   <title>Chapter 5</title>
</head>
<body bgcolor="#FFFFFF">
<table WIDTH="100%" >
<tr>
<td><img SRC="GburgCS.gif" height=84 width=182></td>

<td><font size=+2>CS 391 - Special Topic: Machine Learning</font>
<br><font size=+2>Chapter 5</font></td>
</tr>
</table>

<hr>
<br><b><u>Readings</u></b>
<ul>
  <li>2/24: Sections 5.1-5.2</li>
  <li>2/26: Sections 5.3-5.4</li>
  <li>2/28: Sections 5.5-5.8</li>
</ul>

<b><u>Topics</u></b>
<ul>
  <li>Monte Carlo Policy State- and Action-Value Estimation</li>
  <li>On-/Off-Policy Monte Carlo Control</li>
  <li>Incremental Implementation</li>
</ul>

<b><u>Discussion Questions</u></b>
<p>How do Monte Carlo (MC) methods differ from Dynamic Programming (DP) methods?<br>
What assumption(s) are made by DP methods that are not made by MC methods?<br>
What assumption(s) are made by MC methods that are not made by DP methods?<br>
Describe the first-visit MC method for estimating V^pi.&nbsp; How does the
every-visit MC method differ? <br>


Draw the backup diagram for MC methods.&nbsp; How does it differ from backup
diagrams for DP methods?<br>
Do MC methods bootstrap?&nbsp; Why or why not?<br>
What are three advantages of MC methods over DP methods?<br>
What is the problem of <i>maintaining exploration </i>and how does it relate to
MC estimation of action-values?&nbsp; What is the assumption of <i>exploring
starts </i>(ES)?<br>
Describe the MC ES algorithm.&nbsp; How does it differ from every-visit MC?<br>
What does it mean to be an <i>on-policy </i>versus <i>off-policy </i>method?<br>
How does the e-soft on-policy MC control algorithm of Figure 5.6 differ from the
MC ES algorithm of Figure 5.4?<br>
How does one learn an action-value estimation for one policy from episodes
generated by another policy?<br>
Describe the off-policy MC control algorithm of Figure 5.7.&nbsp; What is <i>w</i>?&nbsp;
What are N(s,a) and D(s,a)?<br>
What is the potential problem of this approach?<br>
How is <i>incremental implementation</i> relevant to MC methods?


<p><b><u>Programming Assignment</u></b>
<p><b><u>HW5</u></b></p>
<p>Due Friday 2/28 at the beginning of class.&nbsp; You are encouraged to work
in pairs.&nbsp; An improvised, informal
presentation of your work may be requested in class.</p>
<p>Implement and test first-visit Monte Carlo policy iteration with an e-soft
policy. Choose one of the following problems:</p>
<ul>
  <li>an episodic, associative problem you have already implemented,</li>
  <li>a gridworld problem(Example 3.8 or 4.1), or</li>
  <li>a pre-approved problem of your choice.</li>
</ul>
<p>You must collect and present experimental data (e.g. learned policies,
performance, etc.).</p>
</body>
</html>
