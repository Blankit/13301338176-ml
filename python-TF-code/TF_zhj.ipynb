{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-51-5912d4268f68>:5: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "1.2\n",
      "Model stored....\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v1 = tf.Variable(1.1, name=\"v1\")\n",
    "v2 = tf.Variable(1.2, name=\"v2\")\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print v2.eval(sess)\n",
    "    save_path=\"/tmp/zhjmodel-1.ckpt\"\n",
    "    saver.save(sess,save_path)\n",
    "    print \"Model stored....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 36\r\n",
      "drwxrwxr-x  2 haijunz haijunz 4096  2月  8 22:45 \u001b[0m\u001b[01;34mc++\u001b[0m/\r\n",
      "-rw-rw-r--  1 haijunz haijunz   83  3月  3 03:47 checkpoint\r\n",
      "drwxrwxr-x 24 haijunz haijunz 4096  2月  8 23:13 \u001b[01;34mmodels\u001b[0m/\r\n",
      "drwxrwxr-x  7 haijunz haijunz 4096  2月  8 00:04 \u001b[01;34mtensorflow\u001b[0m/\r\n",
      "drwxrwxr-x  5 haijunz haijunz 4096  2月 25 13:20 \u001b[01;34mTensorFlow-Examples\u001b[0m/\r\n",
      "-rw-rw-r--  1 haijunz haijunz 2388  3月  3 03:48 TF_zhj.ipynb\r\n",
      "-rw-rw-r--  1 haijunz haijunz    8  3月  3 03:47 zhjmodel.ckpt.data-00000-of-00001\r\n",
      "-rw-rw-r--  1 haijunz haijunz  135  3月  3 03:47 zhjmodel.ckpt.index\r\n",
      "-rw-rw-r--  1 haijunz haijunz 3325  3月  3 03:47 zhjmodel.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "ls -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print v1.eval(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-62-0440993f0ab1>:3: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "100\n",
      "INFO:tensorflow:Restoring parameters from /tmp/zhjmodel-1.ckpt\n",
      "Model restored.\n",
      "1066192077\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "v1 = tf.Variable(100, name=\"v1\")\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print v1.eval(sess)\n",
    "    save_path=\"/tmp/zhjmodel-1.ckpt\"\n",
    "    saver.restore(sess, save_path)\n",
    "    print(\"Model restored.\")\n",
    "    print sess.run(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 76\r\n",
      "drwxrwxr-x  2 haijunz haijunz  4096  2月  8 22:45 \u001b[0m\u001b[01;34mc++\u001b[0m/\r\n",
      "-rw-rw-r--  1 haijunz haijunz    83  3月  3 04:10 checkpoint\r\n",
      "drwxrwxr-x 24 haijunz haijunz  4096  2月  8 23:13 \u001b[01;34mmodels\u001b[0m/\r\n",
      "drwxrwxr-x  7 haijunz haijunz  4096  2月  8 00:04 \u001b[01;34mtensorflow\u001b[0m/\r\n",
      "drwxrwxr-x  5 haijunz haijunz  4096  2月 25 13:20 \u001b[01;34mTensorFlow-Examples\u001b[0m/\r\n",
      "-rw-rw-r--  1 haijunz haijunz 19657  3月  3 04:15 TF_zhj.ipynb\r\n",
      "-rw-rw-r--  1 haijunz haijunz    40  3月  3 04:10 zhjmodel.ckpt.data-00000-of-00001\r\n",
      "-rw-rw-r--  1 haijunz haijunz   274  3月  3 04:10 zhjmodel.ckpt.index\r\n",
      "-rw-rw-r--  1 haijunz haijunz 26859  3月  3 04:10 zhjmodel.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-53-53b7a9795d2f>:8: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "v1 =  1\n",
      "v2 =  2\n",
      "Model saved in file:  /tmp/model-2.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(1, name=\"v1\")\n",
    "v2 = tf.Variable(2, name=\"v2\")\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  print \"v1 = \", v1.eval()\n",
    "  print \"v2 = \", v2.eval()\n",
    "  # Save the variables to disk.\n",
    "  save_path = saver.save(sess, \"/tmp/model-2.ckpt\")\n",
    "  print \"Model saved in file: \", save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model-2.ckpt\n",
      "Model restored.\n",
      "v1 =  1066192077\n",
      "v2 =  1067030938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(0, name=\"v1\")\n",
    "v2 = tf.Variable(0, name=\"v2\")\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"/tmp/model-2.ckpt\")\n",
    "  print \"Model restored.\"\n",
    "  print \"v1 = \", v1.eval()\n",
    "  print \"v2 = \", v2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model-python\n",
    "\n",
    "\n",
    "\n",
    "In( and After) TensorFlow version 0.11.0RC1, you can save and restore your model directly by calling tf.train.export_meta_graph and tf.train.import_meta_graph according to https://www.tensorflow.org/programmers_guide/meta_graph\n",
    "\n",
    "save model:\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')\n",
    "w2 = tf.Variable(tf.truncated_normal(shape=[20]), name='w2')\n",
    "tf.add_to_collection('vars', w1)\n",
    "tf.add_to_collection('vars', w2)\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.save(sess, 'my-model')\n",
    "# `save` method will call `export_meta_graph` implicitly.\n",
    "# you will get saved graph files:my-model.meta\n",
    "restore model:\n",
    "\n",
    "sess = tf.Session()\n",
    "new_saver = tf.train.import_meta_graph('my-model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "all_vars = tf.get_collection('vars')\n",
    "for v in all_vars:\n",
    "    v_ = sess.run(v)\n",
    "    print(v_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my-model'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')\n",
    "w2 = tf.Variable(tf.truncated_normal(shape=[20]), name='w2')\n",
    "tf.add_to_collection('vars', w1)\n",
    "tf.add_to_collection('vars', w2)\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.save(sess, 'my-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my-model\n",
      "[-0.37086406  0.08911986 -0.28879181  1.71345913  0.58238709  0.10466224\n",
      "  1.82971454  0.64682716 -0.04697657 -0.54234552]\n",
      "[ 1.00366652 -0.168256   -0.31289053 -1.52799881  0.65399295  0.28079289\n",
      " -0.43277559 -0.14389682 -0.73241359  0.33028015  0.09534761  1.04325068\n",
      "  1.23532903  0.18246558 -1.93002868  0.12127474  1.53824556 -0.73324728\n",
      "  0.98436594 -0.69227767]\n",
      "[-0.37086406  0.08911986 -0.28879181  1.71345913  0.58238709  0.10466224\n",
      "  1.82971454  0.64682716 -0.04697657 -0.54234552]\n",
      "[ 1.00366652 -0.168256   -0.31289053 -1.52799881  0.65399295  0.28079289\n",
      " -0.43277559 -0.14389682 -0.73241359  0.33028015  0.09534761  1.04325068\n",
      "  1.23532903  0.18246558 -1.93002868  0.12127474  1.53824556 -0.73324728\n",
      "  0.98436594 -0.69227767]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "new_saver = tf.train.import_meta_graph('my-model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "all_vars = tf.get_collection('vars')\n",
    "for v in all_vars:\n",
    "    v_ = sess.run(v)\n",
    "    print(v_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For TensorFlow version lower than 0.11.0RC1, the checkpoints that are saved contain values for the Variables in your model, not the model/graph itself, which means that the graph should be the same when you restore the checkpoint.\n",
    "\n",
    "Here's an example for a linear regression where there's a training loop that saves variable checkpoints and an evaluation section that will restore variables saved in a prior run and compute predictions. Of course, you can also restore variables and continue training if you'd like.\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/state_ops/variables#Variable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two parts to the model, the model definition, saved by Supervisor as graph.pbtxt in the model directory and the numerical values of tensors, saved into checkpoint files like model.ckpt-1003418.\n",
    "\n",
    "The model definition can be restored using tf.import_graph_def, and the weights are restored using Saver.\n",
    "\n",
    "However, Saver uses special collection holding list of variables that's attached to the model Graph, and this collection is not initialized using import_graph_def, so you can't use the two together at the moment (it's on our roadmap to fix). For now, you have to use approach of Ryan Sepassi -- manually construct a graph with identical node names, and use Saver to load the weights into it.\n",
    "\n",
    "(Alternatively you could hack it by using by using import_graph_def, creating variables manually, and using tf.add_to_collection(tf.GraphKeys.VARIABLES, variable) for each variable, then using Saver)\n",
    "\n",
    "As Yaroslav said, you can hack restoring from a graph_def and checkpoint by importing the graph, manually creating variables, and then using a Saver.\n",
    "\n",
    "I implemented this for my personal use, so I though I'd share the code here.\n",
    "\n",
    "Link: https://gist.github.com/nikitakit/6ef3b72be67b86cb7868\n",
    "\n",
    "(This is, of course, a hack, and there is no guarantee that models saved this way will remain readable in future versions of TensorFlow.)\n",
    "\n",
    "\n",
    "\n",
    "If it is an internally saved model, you just specify a restorer for all variables as\n",
    "\n",
    "restorer = tf.train.Saver(tf.all_variables())\n",
    "and use it to restore variables in a current session:\n",
    "\n",
    "restorer.restore(self._sess, model_file)\n",
    "For the external model you need to specify the mapping from the its variable names to your variable names. You can view the model variable names using the command\n",
    "\n",
    "python /path/to/tensorflow/tensorflow/python/tools/inspect_checkpoint.py --file_name=/path/to/pretrained_model/model.ckpt\n",
    "The inspect_checkpoint.py script can be found in './tensorflow/python/tools' folder of the Tensorflow source.\n",
    "\n",
    "To specify the mapping, you can use my Tensorflow-Worklab, which contains a set of classes and scripts to train and retrain different models. It includes an example of retraining ResNet models, located here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If it is an internally saved model, you just specify a restorer for all variables as\n",
    "\n",
    "restorer = tf.train.Saver(tf.all_variables())\n",
    "and use it to restore variables in a current session:\n",
    "\n",
    "restorer.restore(self._sess, model_file)\n",
    "For the external model you need to specify the mapping from the its variable names to your variable names. You can view the model variable names using the command\n",
    "\n",
    "python /path/to/tensorflow/tensorflow/python/tools/inspect_checkpoint.py --file_name=/path/to/pretrained_model/model.ckpt\n",
    "\n",
    "The inspect_checkpoint.py script can be found in './tensorflow/python/tools' folder of the Tensorflow source.\n",
    "\n",
    "To specify the mapping, you can use my Tensorflow-Worklab, which contains a set of classes and scripts to train and retrain different models. It includes an example of retraining ResNet models, located here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also take this easier way.\n",
    "\n",
    "Step.1 - Initialize all your variables\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1), name=\"W1\")\n",
    "B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]), name=\"B1\")\n",
    "\n",
    "Similarly, W2, B2, W3, .....\n",
    "Step.2 - Save the list inside Model Saver and Save it\n",
    "\n",
    "model_saver = tf.train.Saver()\n",
    "\n",
    "# Train the model and save it in the end\n",
    "model_saver.save(session, \"saved_models/CNN_New.ckpt\")\n",
    "Step. 3 - Restore the model\n",
    "\n",
    "with tf.Session(graph=graph_cnn) as session:\n",
    "    model_saver.restore(session, \"saved_models/CNN_New.ckpt\")\n",
    "    print(\"Model restored.\") \n",
    "    print('Initialized')\n",
    "Step. 4 - Check Variable\n",
    "\n",
    "W1 = session.run(W1)\n",
    "print(W1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/sdemyanov/tensorflow-worklab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://stackoverflow.com/questions/37858866/how-to-restore-checkpoint-in-tensorflow-inside-ipython-or-anaconda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You need to reset the default graph at the beginning of your call when you run again the file.\n",
    "\n",
    "If you don't reset the default graph, and run two times the line:\n",
    "\n",
    "x = tf.Variable(1, name='x')\n",
    "print x.name\n",
    "You will see the first time that x has name \"x:0\" and the second time its name is \"x_1:0\". This is what confuses tf.train.Saver:\n",
    "\n",
    "it first saves the value of x using name \"x:0\"\n",
    "then in the next run you try to load the saved value of x, but now the name of the variable is \"x_1:0\", so the saver tries to load a saved value under the name \"x_1:0\" but cannot find it, and returns an error.\n",
    "However, you can reset the default graph at the beginning using tf.reset_default_graph(). This will create an empty graph and use it as default graph.\n",
    "Here the name of x can be the same in those two graphs:\n",
    "\n",
    "# First run\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.Variable(1, name='x')\n",
    "print x.name  # prints 'x:0'\n",
    "\n",
    "# Next run\n",
    "tf.reset_default_graph()\n",
    "x = tf.Variable(1, name='x')\n",
    "print x.name  # prints 'x:0'\n",
    "The two Variables can now have the same name because they are no longer in the same graph.\n",
    "\n",
    "Another way of doing it is to create a graph at the beginning and use it as default graph:\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.Variable(1, name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-68-9f3f1954f157>:7: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "v1 =  11\n",
      "v2 =  2\n",
      "Model saved in file:  /tmp/model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ############### tensor_save_named_vars.py#######################\n",
    "tf.reset_default_graph()\n",
    "v1 = tf.Variable(11, name=\"v1\")\n",
    "v2 = tf.Variable(2, name=\"v2\")\n",
    "\n",
    "# Add an op to initialize the variables.\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, initialize the variables, do some work, save the\n",
    "# variables to disk.\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init_op)\n",
    "  print \"v1 = \", v1.eval()\n",
    "  print \"v2 = \", v2.eval()\n",
    "  # Save the variables to disk.\n",
    "  save_path = saver.save(sess, \"/tmp/model3.ckpt\")\n",
    "  print \"Model saved in file: \", save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "v1 = "
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value v1\n\t [[Node: _send_v1_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-3944280528280342338, tensor_name=\"v1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](v1)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b52c277d48d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m#saver.restore(sess, \"/tmp/model3.ckpt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Model restored.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"v1 = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0;32mprint\u001b[0m \u001b[0;34m\"v2 = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    456\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3727\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3728\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3729\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value v1\n\t [[Node: _send_v1_0 = _Send[T=DT_INT32, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=-3944280528280342338, tensor_name=\"v1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](v1)]]"
     ]
    }
   ],
   "source": [
    "\n",
    "############################ tensor_restore.py######################\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "# Create some variables.\n",
    "v1 = tf.Variable(0, name=\"v1\")\n",
    "v2 = tf.Variable(0, name=\"v2\")\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Later, launch the model, use the saver to restore variables from disk, and\n",
    "# do some work with the model.\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  #saver.restore(sess, \"/tmp/model3.ckpt\")\n",
    "  print \"Model restored.\"\n",
    "  print \"v1 = \", v1.eval()\n",
    "  print \"v2 = \", v2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 haijunz haijunz    8  3月  3 05:07 /tmp/model3.ckpt.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 haijunz haijunz  135  3月  3 05:07 /tmp/model3.ckpt.index\r\n",
      "-rw-rw-r-- 1 haijunz haijunz 3319  3月  3 05:07 /tmp/model3.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "ls -l /tmp/model3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model3.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "new_saver = tf.train.import_meta_graph('/tmp/model3.ckpt.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint('/tmp/'))\n",
    "all_vars = tf.get_collection('vars')\n",
    "for v in all_vars:\n",
    "    v_ = sess.run(v)\n",
    "    print(v_)\n",
    "    print v1.eval()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Scikit Flow get GraphDef for Android (save *.pb file)\n",
    "\n",
    "To save as pb file, you need to extract the graph_def from the constructed graph. You can do that as--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import tensor_shape, graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "sess = tf.Session()\n",
    "final_tensor_name = 'results:0'     #Replace final_tensor_name with name of the final tensor in your graph\n",
    "#########Build your graph and train########\n",
    "## Your tensorflow code to build the graph\n",
    "###########################################\n",
    "\n",
    "outpt_filename = 'output_graph1.pb'\n",
    "output_graph_def = sess.graph.as_graph_def()\n",
    "with gfile.FastGFile(outpt_filename, 'wb') as f:\n",
    "  f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 9268\r\n",
      "-rwxrwxr-x 1 haijunz haijunz 1264936 10月 10 23:58 \u001b[0m\u001b[01;32mA Practical Introduction to Deep Learning with Caffe and Python.pdf\u001b[0m\u001b[K*\r\n",
      "-rwxrwxr-x 1 haijunz haijunz 7290716 10月 10 23:58 \u001b[01;32mMachine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks.pdf\u001b[0m\u001b[K*\r\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:04 \u001b[01;34mmy\u001b[0m/\r\n",
      "-rw-rw-r-- 1 haijunz haijunz    1912 12月  6 04:12 output_graph1.pb\r\n",
      "-rw-rw-r-- 1 haijunz haijunz    1912 12月  6 04:12 output_graph.pb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz  539707 10月 10 23:58 \u001b[01;32mpillow.pdf\u001b[0m*\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   78988 10月 10 23:58 \u001b[01;32mtflearn-zhj.ipynb\u001b[0m*\r\n",
      "-rwxrwxr-x 1 haijunz haijunz    3855 10月 10 23:58 \u001b[01;32mtflearn-zhj-trouble.ipynb\u001b[0m*\r\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:05 \u001b[01;34mtf-model\u001b[0m/\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   72355 12月  6 04:12 \u001b[01;32mTF_zhj.ipynb\u001b[0m*\r\n",
      "-rwxrwxr-x 1 haijunz haijunz  129106 10月 10 23:58 \u001b[01;32mthe-python-imaging-library.pdf\u001b[0m*\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   82865 10月 10 23:58 \u001b[01;32mtitanic_dataset.csv\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to convert your trained variables to constants (to avoid using ckpt files to load the weights), you can use:\n",
    "\n",
    "output_graph_def = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), [final_tensor_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "results:0 is not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a2d7df633313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutpt_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output_graph1.pb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfinal_tensor_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpt_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util_impl.pyc\u001b[0m in \u001b[0;36mconvert_variables_to_constants\u001b[0;34m(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)\u001b[0m\n\u001b[1;32m    200\u001b[0m   \u001b[0;31m# This graph only includes the nodes needed to evaluate the output nodes, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;31m# removes unneeded nodes like those involved in saving and assignment.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m   \u001b[0minference_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_sub_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_node_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0mfound_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util_impl.pyc\u001b[0m in \u001b[0;36mextract_sub_graph\u001b[0;34m(graph_def, dest_nodes)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_to_node_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%s is not in graph\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0mnodes_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: results:0 is not in graph"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import tensor_shape, graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "sess = tf.Session()\n",
    "final_tensor_name = 'results:0'     #Replace final_tensor_name with name of the final tensor in your graph\n",
    "#########Build your graph and train########\n",
    "## Your tensorflow code to build the graph\n",
    "###########################################\n",
    "\n",
    "outpt_filename = 'output_graph.pb'\n",
    "output_graph_def = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), [final_tensor_name])\n",
    "with gfile.FastGFile(outpt_filename, 'wb') as f:\n",
    "  f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow GraphDef pb 文件读和写 \n",
    "http://blog.csdn.net/eunicechen/article/details/51801351\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named Python.platform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0154238c2fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named Python.platform"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os.path\n",
    "\n",
    "from tensorflow.Python.platform import gfile\n",
    "from google.protobuf import text_format\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGs\n",
    "\n",
    "#Input Graph model file location\n",
    "tf.app.flags.DEFINE_string('model_dir', './', \"\"\"Paht to classify_image_graph_def.pb\"\"\")\n",
    "\n",
    "#Output Graph model protobuf as text format & binary format\n",
    "tf.app.flags.DEFINE_string('output_graph_txt', './output_graph.pb.txt', \"\"\"pbtxt\"\"\")\n",
    "tf.app.flags.DEFINE_string('output_graph_pb', './output_graph.pb', \"\"\"pb\"\"\")\n",
    "\n",
    "def convert_pb_to_pbtxt():\n",
    "  model_filename = os.path.join(FLAGS.model_dir, 'classify_image_graph_def.pb')\n",
    "  with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "   graph_def = tf.GraphDef()        #创建一个GraphDef\n",
    "   graph_def.ParseFromString(f.read())   #ParseFromString(), reading message from protocol buffer binary fomat\n",
    "  \n",
    "  with gfile.FastGFile(FLAGS.output_graph_txt, 'wb') as f:\n",
    "   f.write(text_format.MessageToString(graph_def))   # MessageToString(message, as_utf8=False, as_one_line=False)  Convert protobuf message to text format\n",
    "  \n",
    "#  with gfile.FastGFile(FLAGS.output_graph_pb, 'wb') as f:\n",
    "#   f.write(graph_def.SerializeToString())  #serializes the message and returns it as a string. Note that the bytes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  tensorflow从0开始（6）——保存加载模型\n",
    "http://blog.csdn.net/searobbers_duck/article/details/51721916\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('summaries_dir', '/tmp/save_graph_logs', 'Summaries directory')\n",
    "tf.global_variables_initializer\n",
    "data = np.arange(10,dtype=np.int32)\n",
    "with tf.Session() as sess:\n",
    "  print(\"# build graph and run\")\n",
    "  input1= tf.placeholder(tf.int32, [10], name=\"input\")\n",
    "  output1= tf.add(input1, tf.constant(100,dtype=tf.int32), name=\"output\") #  data depends on the input data\n",
    "  saved_result= tf.Variable(data, name=\"saved_result\")\n",
    "  do_save=tf.assign(saved_result,output1)\n",
    "  tf.initialize_all_variables()\n",
    "  os.system(\"rm -rf /tmp/save_graph_logs\")\n",
    "  merged = tf.merge_all_summaries()\n",
    "  train_writer = tf.train.SummaryWriter(FLAGS.summaries_dir,\n",
    "                                        sess.graph)\n",
    "  os.system(\"rm -rf /tmp/load\")\n",
    "  tf.train.write_graph(sess.graph_def, \"/tmp/load\", \"test.pb\", False) #proto\n",
    "  # now set the data:\n",
    "  result,_=sess.run([output1,do_save], {input1: data}) # calculate output1 and assign to 'saved_result'\n",
    "  saver = tf.train.Saver(tf.all_variables())\n",
    "  saver.save(sess,\"checkpoint.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将TensorFlow的网络导出为单个文件发表于 2017-01-14 | \n",
    "http://encodets.me/2017/01/export-TensorFlow-network/\n",
    "\n",
    "有时候，我们需要将TensorFlow的模型导出为单个文件（同时包含模型架构定义与权重），方便在其他地方使用（如在c++中部署网络）。利用tf.train.write_graph()默认情况下只导出了网络的定义（没有权重），而利用tf.train.Saver().save()导出的文件graph_def与权重是分离的，因此需要采用别的方法。\n",
    "\n",
    "我们知道，graph_def文件中没有包含网络中的Variable值（通常情况存储了权重），但是却包含了constant值，所以如果我们能把Variable转换为constant，即可达到使用一个文件同时存储网络架构与权重的目标。\n",
    "\n",
    "我们可以采用以下方式冻结权重并保存网络：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "# 构造网络\n",
    "a = tf.Variable([[3],[4]], dtype=tf.float32, name='a')\n",
    "b = tf.Variable(4, dtype=tf.float32, name='b')\n",
    "# 一定要给输出tensor取一个名字！！\n",
    "output = tf.add(a, b, name='out')\n",
    "# 转换Variable为constant，并将网络写入到文件\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 这里需要填入输出tensor的名字\n",
    "    graph = convert_variables_to_constants(sess, sess.graph_def, [\"out\"])\n",
    "    tf.train.write_graph(graph, '.', 'graph.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 10324\n",
      "-rwxrwxr-x 1 haijunz haijunz 1264936 10月 10 23:58 A Practical Introduction to Deep Learning with Caffe and Python.pdf\n",
      "-rw-rw-r-- 1 haijunz haijunz     253 12月  6 06:14 graph.pb\n",
      "-rw------- 1 haijunz haijunz 1044982 12月  6 04:36 How to use tensorflow pre-trained model in Android - - CSDN博客.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz 7290716 10月 10 23:58 Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks.pdf\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:04 my\n",
      "-rw-rw-r-- 1 haijunz haijunz     118 12月  6 04:37 optimized_graph.pb\n",
      "-rw-rw-r-- 1 haijunz haijunz   17198  2月  7  2017 optimize_for_inference_lib.py\n",
      "-rw-rw-r-- 1 haijunz haijunz    4714  4月  5  2017 optimize_for_inference.py\n",
      "-rw-rw-r-- 1 haijunz haijunz   11252  2月  7  2017 optimize_for_inference_test.py\n",
      "-rwxrwxr-x 1 haijunz haijunz  539707 10月 10 23:58 pillow.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   78988 10月 10 23:58 tflearn-zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz    3855 10月 10 23:58 tflearn-zhj-trouble.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz   69039 12月  6 06:20 TF_zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz  129106 10月 10 23:58 the-python-imaging-library.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   82865 10月 10 23:58 titanic_dataset.csv\n",
      "variables\n"
     ]
    }
   ],
   "source": [
    "! ls -l\n",
    "print tf.GraphKeys.GLOBAL_VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当恢复网络时，可以使用如下方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 7.],\n",
      "       [ 8.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    with open('./graph.pb', 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read()) \n",
    "        output = tf.import_graph_def(graph_def, return_elements=['out:0']) \n",
    "        print(sess.run(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 9260\r\n",
      "-rwxrwxr-x 1 haijunz haijunz 1264936 10月 10 23:58 A Practical Introduction to Deep Learning with Caffe and Python.pdf\r\n",
      "-rw-rw-r-- 1 haijunz haijunz     253 12月  6 04:28 graph.pb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz 7290716 10月 10 23:58 Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks.pdf\r\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:04 my\r\n",
      "-rw-rw-r-- 1 haijunz haijunz     118 12月  6 04:33 optimized_graph.pb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz  539707 10月 10 23:58 pillow.pdf\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   78988 10月 10 23:58 tflearn-zhj.ipynb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz    3855 10月 10 23:58 tflearn-zhj-trouble.ipynb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   65712 12月  6 04:32 TF_zhj.ipynb\r\n",
      "-rwxrwxr-x 1 haijunz haijunz  129106 10月 10 23:58 the-python-imaging-library.pdf\r\n",
      "-rwxrwxr-x 1 haijunz haijunz   82865 10月 10 23:58 titanic_dataset.csv\r\n"
     ]
    }
   ],
   "source": [
    "! python -m tensorflow.python.tools.optimize_for_inference \\\n",
    "  --input=graph.pb \\\n",
    "  --output=optimized_graph.pb \\\n",
    "  --input_names=\"a\" \\\n",
    "  --input_names=\"b\" \\\n",
    "  --output_names=\"out\"\n",
    "\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named scripts\n",
      "总用量 9260\n",
      "-rwxrwxr-x 1 haijunz haijunz 1264936 10月 10 23:58 A Practical Introduction to Deep Learning with Caffe and Python.pdf\n",
      "-rw-rw-r-- 1 haijunz haijunz     253 12月  6 04:28 graph.pb\n",
      "-rwxrwxr-x 1 haijunz haijunz 7290716 10月 10 23:58 Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks.pdf\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:04 my\n",
      "-rw-rw-r-- 1 haijunz haijunz     118 12月  6 04:33 optimized_graph.pb\n",
      "-rwxrwxr-x 1 haijunz haijunz  539707 10月 10 23:58 pillow.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   78988 10月 10 23:58 tflearn-zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz    3855 10月 10 23:58 tflearn-zhj-trouble.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz   67169 12月  6 04:34 TF_zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz  129106 10月 10 23:58 the-python-imaging-library.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   82865 10月 10 23:58 titanic_dataset.csv\n"
     ]
    }
   ],
   "source": [
    " ! python -m scripts.quantize_graph \\\n",
    "  --input=optimized_graph.pb \\\n",
    "  --output=rounded_graph.pb \\\n",
    "  --output_node_names=out \\\n",
    "  --mode=weights_rounded\n",
    "    \n",
    " ! ls -l   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到之前的权重确实保存了下来!! ,  save as Txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "a = tf.Variable([[3],[4]], dtype=tf.float32, name='a')\n",
    "b = tf.Variable(4, dtype=tf.float32, name='b')\n",
    "input_tensor = tf.placeholder(tf.float32, name='input')\n",
    "output = tf.add((a+b), input_tensor, name='out')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    graph = convert_variables_to_constants(sess, sess.graph_def, [\"out\"])\n",
    "    tf.train.write_graph(graph, '.', 'graph.pb.txt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 9280\n",
      "-rwxrwxr-x 1 haijunz haijunz 1264936 10月 10 23:58 A Practical Introduction to Deep Learning with Caffe and Python.pdf\n",
      "-rw-rw-r-- 1 haijunz haijunz     253 12月  6 04:19 graph.pb\n",
      "-rw-rw-r-- 1 haijunz haijunz    1191 12月  6 04:20 graph.pb.txt\n",
      "-rwxrwxr-x 1 haijunz haijunz 7290716 10月 10 23:58 Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks.pdf\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:04 my\n",
      "-rw-rw-r-- 1 haijunz haijunz    1912 12月  6 04:12 output_graph1.pb\n",
      "-rw-rw-r-- 1 haijunz haijunz    1912 12月  6 04:12 output_graph.pb\n",
      "-rwxrwxr-x 1 haijunz haijunz  539707 10月 10 23:58 pillow.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   78988 10月 10 23:58 tflearn-zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz    3855 10月 10 23:58 tflearn-zhj-trouble.ipynb\n",
      "drwxrwxr-x 2 haijunz haijunz    4096 12月  6 04:05 tf-model\n",
      "-rwxrwxr-x 1 haijunz haijunz   73823 12月  6 04:18 TF_zhj.ipynb\n",
      "-rwxrwxr-x 1 haijunz haijunz  129106 10月 10 23:58 the-python-imaging-library.pdf\n",
      "-rwxrwxr-x 1 haijunz haijunz   82865 10月 10 23:58 titanic_dataset.csv\n",
      "node {\n",
      "  name: \"a\"\n",
      "  op: \"Const\"\n",
      "  attr {\n",
      "    key: \"dtype\"\n",
      "    value {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "  attr {\n",
      "    key: \"value\"\n",
      "    value {\n",
      "      tensor {\n",
      "        dtype: DT_FLOAT\n",
      "        tensor_shape {\n",
      "          dim {\n",
      "            size: 2\n",
      "          }\n",
      "          dim {\n",
      "            size: 1\n",
      "          }\n",
      "        }\n",
      "        tensor_content: \"\\000\\000@@\\000\\000\\200@\"\n",
      "\u001b[7m--更多--(30%)\u001b[m"
     ]
    }
   ],
   "source": [
    "! ls -l\n",
    "! more graph.pb.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题来了，我们的网络需要能有一个输入自定义数据的接口啊！不然这玩意有什么用。。别急，当然有办法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 2 variables.\n",
      "Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "\n",
    "tf.reset_default_graph()\n",
    "a = tf.Variable([[3],[4]], dtype=tf.float32, name='a')\n",
    "b = tf.Variable(4, dtype=tf.float32, name='b')\n",
    "input_tensor = tf.placeholder(tf.float32, name='input')\n",
    "output = tf.add((a+b), input_tensor, name='out')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    graph = convert_variables_to_constants(sess, sess.graph_def, [\"out\"])\n",
    "    tf.train.write_graph(graph, '.', 'graph.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上述代码重新保存网络至graph.pb，这次我们有了一个输入placeholder，下面来看看怎么恢复网络并输入自定义数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 11.],\n",
      "       [ 12.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    with open('./graph.pb', 'rb') as f: \n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read()) \n",
    "        output = tf.import_graph_def(graph_def, input_map={'input:0':4.}, return_elements=['out:0'], name='a') \n",
    "        print(sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到结果没有问题，当然在input_map那里可以替换为新的自定义的placeholder，如下所示：看看输出，同样没有问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 11.],\n",
      "       [ 12.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "new_input = tf.placeholder(tf.float32, shape=())\n",
    "with tf.Session() as sess:\n",
    "    with open('./graph.pb', 'rb') as f: \n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read()) \n",
    "        output = tf.import_graph_def(graph_def, input_map={'input:0':new_input}, return_elements=['out:0'], name='a') \n",
    "        print(sess.run(output, feed_dict={new_input:4}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外需要说明的一点是，在利用tf.train.write_graph写网络架构的时候，如果令as_text=True了，则在导入网络的时候，需要做一点小修改。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "2:1 : Expected identifier or number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-90ec8c0ac710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# 不使用graph_def.ParseFromString(f.read())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtext_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out:0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36mMerge\u001b[0;34m(text, message, allow_unknown_extension, allow_field_number, descriptor_pool)\u001b[0m\n\u001b[1;32m    474\u001b[0m       \u001b[0mallow_unknown_extension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m       \u001b[0mallow_field_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m       descriptor_pool=descriptor_pool)\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(lines, message, allow_unknown_extension, allow_field_number, descriptor_pool)\u001b[0m\n\u001b[1;32m    524\u001b[0m                    \u001b[0mallow_field_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                    descriptor_pool=descriptor_pool)\n\u001b[0;32m--> 526\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMergeLines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36mMergeLines\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;34m\"\"\"Merges a text representation of a protocol message into a message.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_multiple_scalars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ParseOrMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36m_ParseOrMerge\u001b[0;34m(self, lines, message)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAtEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_MergeField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36m_MergeField\u001b[0;34m(self, tokenizer, message)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConsumeIdentifierOrNumber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_field_number\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseInteger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/protobuf/text_format.pyc\u001b[0m in \u001b[0;36mConsumeIdentifierOrNumber\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IDENTIFIER_OR_NUMBER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected identifier or number.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNextToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseError\u001b[0m: 2:1 : Expected identifier or number."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\t# 不使用'rb'模式\n",
    "    with open('./graph.pb', 'r') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        # 不使用graph_def.ParseFromString(f.read())\n",
    "        text_format.Merge(f.read(), graph_def)\n",
    "        output = tf.import_graph_def(graph_def, return_elements=['out:0']) \n",
    "        print(sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##参考资料http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://blog.csdn.net/searobbers_duck/article/details/51721916 \n",
    "tensorflow从0开始（6）——保存加载模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 徐长卿学数据分析http://www.cnblogs.com/SSSR/p/5630534.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there an example on how to generate protobuf files holding trained Tensorflow graphs\n",
    "\n",
    "\n",
    "http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow\n",
    "\n",
    "I am looking at Google's example on how to deploy and use a pre-trained Tensorflow graph (model) on Android, at:\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\n",
    "\n",
    "This example uses a .pb file at: [this is a link to a file that downloads automatically] https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n",
    "\n",
    "The example shows how to load the .pb file to a Tensorflow session and use it to perform classification, but it doesn't (?) mention how to generate such a .pb file after a graph is trained (e.g., in Python).\n",
    "\n",
    "Are there any examples on how to do that?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
