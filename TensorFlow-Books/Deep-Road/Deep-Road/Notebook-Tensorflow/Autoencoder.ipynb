{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自编码\n",
    "\n",
    "自编码器属于无监督模型, 不需要标注的数据, 用自身的高阶特征来编码自己.\n",
    "\n",
    "这里涉及到稀疏编码, 所谓稀疏编码, 就是把高阶特征分解为低阶特征来稀疏表示.\n",
    "\n",
    "可以把神经网络的前向过程看做从低阶特征向高阶特征过渡.\n",
    "\n",
    "那么稀疏编码是反过来的过程, 从高阶特征向低阶特征转移. Sparce Encoding, 这里的稀疏可以是双向的.\n",
    "\n",
    "在计算机视觉中, 我们需要从像素这样的低阶特征中学习高阶特征, 所谓编码就是从高阶到低阶过渡, 从而压缩信息, 自编码器的关键在编码, 用自身的高阶特征来编码自己. 特点如下\n",
    "\n",
    "1. 希望输入输出一致\n",
    "2. 希望使用高阶特征来重构自己.\n",
    "\n",
    "DBN第一次使得训练深层网络成为可能.\n",
    "\n",
    "从原始的自编码引入一些限制, 可以有一个特性.\n",
    "\n",
    "1. 中间节点数目小于输入节点, 相当于降维.\n",
    "2. 在输入数据中加入噪声, 就成了去噪自编码器. 常用的噪声是加性高斯噪声(Additive Gaussian Noise, AGN), 记忆Masking Noise, 即有随机遮挡的噪声, 这种情况下, 图像中的一部分像素被置0, 自编码器需要从其它像素的结构来推断被遮挡的像素, 因此依然需要学习高阶特征.\n",
    "\n",
    "如果中间只有一层的话, 那么就相当于PCA, DBN中间有很多隐含层, 每一个隐含层都是一个RMB, 训练时, 对每两层之间进行无监督学习, 相当于多层的自编码器, 提取特征初始化网络权重, 最后在进行有监督的反向传播训练, 解决了梯度弥散问题. 这里相当于进行预训练.\n",
    "\n",
    "主要的作用\n",
    "\n",
    "1. 特征提取\n",
    "2. 预训练\n",
    "\n",
    "一般用的都是去噪自编码器. 更进一步的有变分自编码器.其特征如下\n",
    "\n",
    "1. 对中间节点的分布有强假设\n",
    "2. 有额外的损失项\n",
    "3. 使用SGVB(Stochastic Gradient Variational Bayes)\n",
    "4. 与GAN一起作为强大的生成模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用到一个比较常用的网络参数初始化方法, xavier initialization. 利用网络输出输出节点个数, 使得网络权重的均值等于0, 同时方差等于$\\frac{2}{n_{in}+n_{out}}$, 生成方法可以利用高斯分布或者均匀分布, 如果是均匀分布, 则可以利用$(-\\sqrt{\\frac{6}{n_{in}+n_{out}}},\\sqrt{\\frac{6}{n_{in}+n_{out}}})$, 方差利用公式$\\frac{(max-min)^2}{12}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as prep\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "def xavier_init(fan_in, fan_out, constant = 1):\n",
    "    low = -constant * np.sqrt(6.0 /(fan_in + fan_out))\n",
    "    high = constant * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), minval = low, maxval = high, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdditiveGaussianNoiseAutoencoder(object):\n",
    "    def __init__(self, n_input, n_hidden, transfer_function = tf.nn.softplus, optimizer = tf.train.AdamOptimizer(),\n",
    "                 scale = 0.1):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "\n",
    "        # model\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x + scale * tf.random_normal((n_input,)),\n",
    "                self.weights['w1']),\n",
    "                self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n",
    "\n",
    "        # cost\n",
    "        self.cost = 0.5 * tf.reduce_sum(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype = tf.float32))\n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype = tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype = tf.float32))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer), feed_dict = {self.x: X,\n",
    "                                                                            self.scale: self.training_scale\n",
    "                                                                            })\n",
    "        return cost\n",
    "\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict = {self.x: X,\n",
    "                                                     self.scale: self.training_scale\n",
    "                                                     })\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.hidden, feed_dict = {self.x: X,\n",
    "                                                       self.scale: self.training_scale\n",
    "                                                       })\n",
    "\n",
    "    def generate(self, hidden = None):\n",
    "        if hidden is None:\n",
    "            hidden = np.random.normal(size = self.weights[\"b1\"])\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.hidden: hidden})\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.sess.run(self.reconstruction, feed_dict = {self.x: X,\n",
    "                                                               self.scale: self.training_scale\n",
    "                                                               })\n",
    "\n",
    "    def getWeights(self):\n",
    "        return self.sess.run(self.weights['w1'])\n",
    "\n",
    "    def getBiases(self):\n",
    "        return self.sess.run(self.weights['b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_scale(X_train, X_test):\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def get_random_block_from_data(data, batch_size):\n",
    "    start_index = np.random.randint(0, len(data) - batch_size)\n",
    "    return data[start_index:(start_index + batch_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = int(mnist.train.num_examples)\n",
    "training_epochs = 20\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder = AdditiveGaussianNoiseAutoencoder(n_input = 784,\n",
    "                                               n_hidden = 200,\n",
    "                                               transfer_function = tf.nn.softplus,\n",
    "                                               optimizer = tf.train.AdamOptimizer(learning_rate = 0.001),\n",
    "                                               scale = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_10_by_10_images(images):\n",
    "    \"\"\" Plot 100 MNIST images in a 10 by 10 table. Note that we crop\n",
    "    the images so that they appear reasonably close together.  The\n",
    "    image is post-processed to give the appearance of being continued.\"\"\"\n",
    "    images = np.array([np.reshape(image, (28,28)) for image in images])\n",
    "    fig = plt.figure()\n",
    "    #images = [image[3:25, 3:25] for image in images]\n",
    "    #image = np.concatenate(images, axis=1)\n",
    "    for x in range(10):\n",
    "        for y in range(10):\n",
    "            ax = fig.add_subplot(10, 10, 10*y+(x+1))\n",
    "            ax.matshow(images[10*y+x], cmap = matplotlib.cm.binary)\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0f18c3b4b8cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mreconstruct_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mplot_10_by_10_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruct_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%04d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cost=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:.9f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-74913508436b>\u001b[0m in \u001b[0;36mplot_10_by_10_images\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      4\u001b[0m     image is post-processed to give the appearance of being continued.\"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#images = [image[3:25, 3:25] for image in images]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#image = np.concatenate(images, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs = get_random_block_from_data(X_train, batch_size)\n",
    "\n",
    "        # Fit training using batch data\n",
    "        cost = autoencoder.partial_fit(batch_xs)\n",
    "        # Compute average loss\n",
    "        avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0 or epoch == 0:\n",
    "        batch_xs = batch_xs[:100]\n",
    "        reconstruct_img = autoencoder.reconstruct(batch_xs)\n",
    "        plot_10_by_10_images(reconstruct_img)\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "print(\"Total cost: \" + str(autoencoder.calc_total_cost(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder作为深度学习在无监督学习中的应用是非常成功的, 可以用来为模型初始化参数, 但是现在用的比较少了, 可以用来提取高阶特征."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "为了防止深层网络的过拟合, 一般有三种方法(DAR)\n",
    "\n",
    "1. Dropout\n",
    "2. Adam, AdaGrad(改进的随机梯度算法)\n",
    "3. ReLu\n",
    "\n",
    "其中Dropout相当于随机丢弃某一层的输出数据, 相当于创造出很多的随机样本, 通过增大样本量, 减少特征数目来防止过拟合, 也是一种bagging方法.\n",
    "\n",
    "MLP可以解决XOR问题, 因为XOR问题是线性不可分的, 引入隐含层之后可以学习非线性的曲线来进行划分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.9785\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "in_units = 784\n",
    "h1_units = 300\n",
    "W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([h1_units]))\n",
    "W2 = tf.Variable(tf.zeros([h1_units, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, in_units])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "hidden1_drop = tf.nn.dropout(hidden1, keep_prob)\n",
    "y = tf.nn.softmax(tf.matmul(hidden1_drop, W2) + b2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(cross_entropy)\n",
    "\n",
    "# Train\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(3000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  train_step.run({x: batch_xs, y_: batch_ys, keep_prob: 0.75})\n",
    "\n",
    "# Test trained model\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
