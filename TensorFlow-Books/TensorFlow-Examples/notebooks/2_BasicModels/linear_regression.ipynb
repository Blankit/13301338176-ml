{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A linear regression learning algorithm example using TensorFlow library.\n",
    "\n",
    "# Author: Aymeric Damien\n",
    "# Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.6 (default, Oct 26 2016, 20:30:19) \n",
      "Type \"copyright\", \"credits\" or \"license\" for more information.\n",
      "\n",
      "IPython 5.1.0 -- An enhanced Interactive Python.\n",
      "?         -> Introduction and overview of IPython's features.\n",
      "%quickref -> Quick reference.\n",
      "help      -> Python's own help system.\n",
      "object?   -> Details about 'object', use 'object??' for extra details.\n",
      "\n",
      "In [1]: help\n",
      "Out[1]: \n",
      "Type help() for interactive help, or help(object) for help about object.\n",
      "\n",
      "In [2]: rng\n",
      "Out[2]: \n",
      "<module 'numpy.random' from '/usr/local/lib/python2.7/dist-packages/numpy/random/__init__.pyc'>\n",
      "\n",
      "In [3]: print rng\n",
      "<module 'numpy.random' from '/usr/local/lib/python2.7/dist-packages/numpy/random/__init__.pyc'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython \n",
    "\n",
    "IPython.embed()\n",
    "rng = numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 0.091560625 W= 0.317236 b= 0.314854\n",
      "Epoch: 0100 cost= 0.089873463 W= 0.313213 b= 0.343795\n",
      "Epoch: 0150 cost= 0.088381350 W= 0.309429 b= 0.371015\n",
      "Epoch: 0200 cost= 0.087061703 W= 0.30587 b= 0.396616\n",
      "Epoch: 0250 cost= 0.085894726 W= 0.302523 b= 0.420694\n",
      "Epoch: 0300 cost= 0.084862679 W= 0.299375 b= 0.443341\n",
      "Epoch: 0350 cost= 0.083949998 W= 0.296414 b= 0.46464\n",
      "Epoch: 0400 cost= 0.083142869 W= 0.29363 b= 0.484674\n",
      "Epoch: 0450 cost= 0.082429200 W= 0.291011 b= 0.503514\n",
      "Epoch: 0500 cost= 0.081798114 W= 0.288548 b= 0.521234\n",
      "Epoch: 0550 cost= 0.081240028 W= 0.286231 b= 0.537901\n",
      "Epoch: 0600 cost= 0.080746531 W= 0.284052 b= 0.553577\n",
      "Epoch: 0650 cost= 0.080310173 W= 0.282002 b= 0.568321\n",
      "Epoch: 0700 cost= 0.079924352 W= 0.280075 b= 0.582188\n",
      "Epoch: 0750 cost= 0.079583190 W= 0.278262 b= 0.59523\n",
      "Epoch: 0800 cost= 0.079281561 W= 0.276556 b= 0.607498\n",
      "Epoch: 0850 cost= 0.079014950 W= 0.274953 b= 0.619034\n",
      "Epoch: 0900 cost= 0.078779235 W= 0.273445 b= 0.629883\n",
      "Epoch: 0950 cost= 0.078570880 W= 0.272026 b= 0.640087\n",
      "Epoch: 1000 cost= 0.078386620 W= 0.270692 b= 0.649684\n",
      "Optimization Finished!\n",
      "Training cost= 0.0783866 W= 0.270692 b= 0.649684 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print \"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n'\n",
    "    saver.save(sess, 'model-linear')\n",
    "    \n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Regression result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总用量 140\r\n",
      "-rw-rw-r-- 1 haijunz haijunz    81  4月 12 20:58 checkpoint\r\n",
      "-rw-rw-r-- 1 haijunz haijunz 62045  4月 12 20:57 linear_regression.ipynb\r\n",
      "-rw-rw-r-- 1 haijunz haijunz  5086  4月 12 20:23 logistic_regression.ipynb\r\n",
      "drwxr-xr-x 2 haijunz haijunz  4096  4月 12 20:39 MNIST_data\r\n",
      "-rw-rw-r-- 1 haijunz haijunz     8  4月 12 20:51 model-2.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 haijunz haijunz   136  4月 12 20:51 model-2.index\r\n",
      "-rw-rw-r-- 1 haijunz haijunz  6245  4月 12 20:51 model-2.meta\r\n",
      "-rw-rw-r-- 1 haijunz haijunz     8  4月 12 20:58 model-linear.data-00000-of-00001\r\n",
      "-rw-rw-r-- 1 haijunz haijunz   142  4月 12 20:58 model-linear.index\r\n",
      "-rw-rw-r-- 1 haijunz haijunz 19111  4月 12 20:58 model-linear.meta\r\n",
      "-rw-rw-r-- 1 haijunz haijunz 14508  4月 12 20:54 nearest_neighbor.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
